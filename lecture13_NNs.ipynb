{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    a = []\n",
    "    for item in x:\n",
    "        a.append(1/(1+math.exp(-item)))\n",
    "    return a\n",
    "x = np.arange(-10., 10., 0.2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h2>Neural Networks</h2>\n",
    "<p style=\"text-align:center\">\n",
    "Natural Language Processing<br>\n",
    "(COM4513/6513)<br>\n",
    "<br>\n",
    "<a href=\"http://andreasvlachos.github.io\">Andreas Vlachos</a><br>\n",
    "a.vlachos@sheffield.ac.uk<br>\n",
    "<small>Department of Computer Science<br>\n",
    "University of Sheffield\n",
    "</small>\n",
    "</p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In this lecture\n",
    "\n",
    "Neural networks:\n",
    "- a learning paradigm that is driving a lot of the recent progress in the field\n",
    "- comes with many names: deep learning, representation learning, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Have we seen any so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Skip-gram\n",
    "\n",
    "<img src=\"images/skipgram.png\"  style=\"width:950px;\">\n",
    "\n",
    "Given the word in the middle predict each of the context words through their embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Perceptron reminder</h3>\n",
    "<a href=\"https://blog.dbrgn.ch/2013/3/26/perceptrons-in-python/\"><img src=\"images/perceptron.png\" style=\"width:600px; background:none; border:none; box-shadow:none;\" /></a>\n",
    "\n",
    "$$\\hat y = sign(\\sum_{n=1}^N w_nx_n) = sign(\\mathbf{w} \\cdot \\mathbf{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>Logistic regression reminder</h3>\n",
    "\n",
    "<p>Logistic regression (binary):\n",
    "$$P(y=1| \\mathbf{x};\\mathbf{w}) = \\sigma(\\mathbf{w} \\cdot \\mathbf{x}) =  \\frac{1}{1+\\exp( - \\mathbf{w} \\cdot \\mathbf{x})} $$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The most basic neural network:\n",
    "- an input layer, $\\mathbf{x}$\n",
    "- (learned) weights $\\mathbf{w}$ (includes $bias$)\n",
    "- activation function, sigmoid $\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3lcEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f63ac9710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,sigmoid(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limitations of linear models\n",
    "\n",
    "Linear classifiers are useful in a variety of tasks.\n",
    "\n",
    "But what are their limitations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/linearlySep.jpg\" style=\"width:400px; float:left\" />\n",
    "<img src=\"images/nonLinearlySep.jpg\" style=\"width:400px; float:right\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The righthand dataset is not linearly separable and cannot be learned with a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intuition\n",
    "\n",
    "<img src=\"images/nonLinearlySep.jpg\"/>\n",
    "\n",
    "Decompose the problem in 3 binary tasks:\n",
    "- top-right red circles vs. rest\n",
    "- bottom-left red circles vs. rest\n",
    "- the actual task using the above as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multilayer perceptron\n",
    "\n",
    "with one hidden layer consisting of two units (neurons):\n",
    "\t\t\t\t\n",
    "<img src=\"images/hiddenLayerNN.jpg\" style=\"width:650px;\" />\n",
    "\n",
    "\\begin{align}\n",
    "h_1(\\mathbf{x},\\theta_1,\\theta_2, b_1) & = \\sigma(\\theta_1 x_1 + \\theta_2 x_2 + b_1 )\\\\\n",
    "h_2(\\mathbf{x},\\theta_3,\\theta_4, b_2) & = \\sigma(\\theta_3 x_1 + \\theta_4 x_2 + b_2 )\\\\\n",
    "f(\\mathbf{x},\\pmb{\\theta}, \\mathbf{b}, \\pmb{\\omega}, c) & = \\sigma(\\omega_1 h_1(\\mathbf{x},\\mathbf{\\theta}, b_1) + \\omega_2 h_2(\\mathbf{x},\\mathbf{\\theta}, b_2) + c )\\\\\n",
    "\\end{align}\n",
    "\n",
    "$h_1$ and $h_2$ are the input (**learned features**) for the final (classification) layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training\n",
    "\n",
    "What $\\mathbf{w}=\\{\\pmb{\\theta}, \\pmb{\\omega}, \\mathbf{b}, c\\}$ best fits $D_{train} = \\{(x_1,y_1)... (x_N, y_N)\\}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The $\\mathbf{w}^{\\star} \\in \\cal \\Re^d$ ($d=$ number of features) maximizing log-likelihood:\n",
    "\n",
    "$$\\mathbf{w}^{\\star} = \\mathop{\\arg \\max}\\limits_{\\mathbf{w}} L(\\mathbf{w};D_{train}) = \\mathop{\\arg \\max}\\limits_{\\mathbf{w}} \\sum_{n=1}^N \\log f(y_n|x_n;\\mathbf{w})$$\n",
    "\n",
    "Not enough to avoid mistakes, make them unlikely!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sounds familiar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient-based optimization\n",
    "\n",
    "<a href=\"http://bestmaths.net/online/index.php/year-levels/year-12/year-12-topic-list/first-principles/\"><img src=\"images/Y12_Differentiation_from_First_Principles_02.gif\"></a>\n",
    "\n",
    "$f(x)=x^2$\n",
    "\n",
    "$\\nabla_x f(x) = 2x$\n",
    "\n",
    "$f(x)$ is convex, thus if $\\nabla_x f(x_k) = 0$ then $x_k = \\mathop{\\arg \\max}\\limits_{x \\in \\Re} f(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gradient descent\n",
    "<p style=\"border:3px; width:1000px; border-radius: 25px; background-color:lightgrey; border-style:solid; border-color:black; padding: 0.3em;\">\n",
    "\\begin{align}\n",
    "& \\textbf{Input:} \\; D_{train} = \\{(x_1,y_1)...(x_N,y_N)\\}, learning \\; rate\\; \\alpha\\\\\n",
    "& initialize\\; \\mathbf{w} \\\\\n",
    "& \\mathbf{while} \\; not \\; converged \\; \\mathbf{do}\\\\\n",
    "& \\quad update \\; \\mathbf{w} = \\mathbf{w} - \\alpha \\nabla_{\\mathbf{w}} NLL(\\mathbf{w};D_{train}) \\\\\n",
    "& \\mathbf{return} \\; \\mathbf{w}\n",
    "\\end{align}\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- minimizing the negative log likelihood ($NLL$) = maximize the likelihood\n",
    "- learning rate shouldn't be too big; more advanced methods adapt it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training\n",
    "\n",
    "<img src=\"images/hiddenLayerNN.jpg\" style=\"width:450px; background:none; border:none; box-shadow:none;\" />\n",
    "\n",
    "How to learn:\n",
    "- $\\mathbf{\\theta}$ if we do not know what their outputs $h_1, h_2$ should be?\n",
    "- $\\mathbf{\\omega}$  if we do not know the inputs $h_1, h_2$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Backpropagation**: in every SGD iteration:\n",
    "- model calculates intermediate and final values (forward step)\n",
    "- use them to calculate the gradients (back-propagate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backpropagation\n",
    "\n",
    "<p style=\"border:3px; width: 900px; border-radius: 25px; background-color:lightgrey; border-style:solid; border-color:black; padding: 0.3em;\">\n",
    "\\begin{align}\n",
    "& \\textbf{Input:} \\; D_{train} = \\{(\\mathbf{x}^1,y^1)...(\\mathbf{x}^M,y^M)\\}\\\\\n",
    "& initialize\\; randomly \\; \\mathbf{\\theta}, \\mathbf{\\omega}, \\mathbf{b}, c  \\\\\n",
    "& \\mathbf{for} \\; (\\mathbf{x},y) \\in D_{train} \\; \\mathbf{do}\\\\\n",
    "& \\quad predict  \\; \\hat y, hidden_1, hidden_2 = f(\\mathbf{x},\\mathbf{\\theta}, \\mathbf{b}, \\omega_1, \\omega_2, c) \\\\\n",
    "& \\quad calculate \\; loss \\; l=L(\\hat y, y)\\\\\n",
    "& \\quad backpropagate\\; l \\; via\\; gradients: update \\; \\mathbf{\\omega}, c; update \\; \\mathbf{\\theta},\\mathbf{\\beta}\\\\\n",
    "& \\mathbf{return} \\; w\n",
    "\\end{align}\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Non-linearity\n",
    "\n",
    "<!--TODO: explain via linear function, anything that is not y=ax+b-->\n",
    "...matters. Without a non-linear activation function  hidden layers are not helpful.\n",
    "\n",
    "[Let's play](http://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4&seed=0.24754&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation tips\n",
    "\n",
    "- Learning objective non-convex: initialization matters\n",
    "- start with small non-zero values\n",
    "- random restarts to escape local optima\n",
    "\n",
    "- greater learning capacity makes overfitting more likely: regularize\n",
    "\n",
    "- check gradient implementation using numeric differentiation\n",
    "\n",
    "- many software toolkits are available to use: Tensorflow, Theano, Torch etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A bit of history\n",
    "\n",
    "XOR and AI winter\n",
    "\n",
    "Kernel methods (SVMs) in the 90's and early 00's overtook NNs in popularity for two reasons:\n",
    "- theoretical guarantees\n",
    "- computers were not powerful enough\n",
    "\n",
    "Empirical success and faster computers changed this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A personal note : when I was an MSc student, I was told that NNs\tbelonged to the past..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bibliography\n",
    "\n",
    "- A [simple implementation](http://iamtrask.github.io/2015/07/12/basic-python-network/) in python of backpropagation for a multilayer perceptron\n",
    "- A [presentation](http://lxmls.it.pt/2016/Deep-Neural-Networks-Are-Our-Friends.pdf) by Wang Ling explaining it differently as a computation graph \n",
    "- The lecture followed the [tutorial](http://cs.stanford.edu/~quocle/tutorial1.pdf) of Quoc V. Le\n",
    "- A nice, full-fledged explanation of [back-propagation](http://cs231n.github.io/optimization-2/)\n",
    "- Similar material from an NLP perspective is covered in Yoav Goldberg's [tutorial](http://u.cs.biu.ac.il/~yogo/nnlp.pdf), sections 3-6\n",
    "- Chapter 6, 7 and 8 from the just released [deep learning book](http://www.deeplearningbook.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Coming up next\n",
    "\n",
    "The most common neural network architecture in NLP:\n",
    "\n",
    "Recurrent neural networks"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "livereveal": {
   "start_slideshow_at": "selected",
   "theme": "solarized",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
